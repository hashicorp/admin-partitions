Note: These scripts use environmental variables which only apply to a single terminal session. Therefore run the scripts and commands in these steps 
within the same terminal.


#################
#CONSUL SERVER
#################

1) Run install_consul_server.sh to deploy Consul Server

  ./install_consul_server.sh

2) Get External-IP (or DNS name) of the Consul server's "consul-consul-partition-service" 
  
  kubectl get services consul-consul-partition-service
  NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP                                                                                                                                            
  consul-consul-partition-service      LoadBalancer   172.20.138.45    a45c0d48015ed418fbebb1154604f20c-163347652.eu-north-1.elb.amazonaws.com    
  
  
  
  Note: On a notepad, copy/paste the External-IP of the "consul-consul-partition-service". We will use in the next couple of steps.


#################
#CONSUL CLIENT 1
#################

  
3) Get DNS name of EKS API Server of Client 1. Copy/paste the output onto a notepad. We will use this to get the next step.
   
   kubectl config view -o jsonpath="{.clusters[?(@.name=='$EKS_CLUSTER_CLIENT1_CTX')].cluster.server}" | sed 's/https:\/\///'

4) Edit helm-client-team1.yaml file:
  
   a) Edit both the "hosts" and "join" fields to reflect the External-IP (or DNS name) of the consul-consul-partition-service on the Server EKS cluster. 
      You should have noted the External-IP was mentioned in the previous step 2.
      
   b) Edit the "k8sAuthMethodHost" field to reflect the EKS API server's IP/DNS name of the Client 1 EKS Cluster. 
      You retreived the EKS API server DNS name from step 3. 
      
  
  Example inputs for the helm-client-team1.yaml file:
  
  externalServers:
    enabled: true
    hosts: [ "a45c0d48015ed418fbebb1154604f20c-163347652.eu-north-1.elb.amazonaws.com" ]
    tlsServerName: server.dc1.consul
    k8sAuthMethodHost: "E9122C19C8B28D0DFBC6E0C7DDF16B4D.yl4.eu-north-1.eks.amazonaws.com"
  ...
  client:
    enabled: true
    exposeGossipPorts: true
    join: [ "a45c0d48015ed418fbebb1154604f20c-163347652.eu-north-1.elb.amazonaws.com" ]


5) Run install_consul_client1.sh script to deploy Consul Client 1

  ./install_consul_client1.sh
  
  
  

#################
#CONSUL CLIENT 2
#################

6) Get DNS name of EKS API Server of Client 2. Make a note of the output. We will use this to get the next step.
   
   kubectl config view -o jsonpath="{.clusters[?(@.name=='$EKS_CLUSTER_CLIENT2_CTX')].cluster.server}" | sed 's/https:\/\///'

7) Edit helm-client-team2.yaml file:
  
   a) Edit both the "hosts" and "join" fields to reflect the External-IP (or DNS name) of the consul-consul-partition-service on the Server EKS cluster. 
      You should have noted the External-IP was mentioned in the previous step 2.
      
   b) Edit the "k8sAuthMethodHost" field to reflect the EKS API server's IP/DNS name of the Client 2 EKS Cluster. 
      You retreived the EKS API server DNS name from step 6. 
      
      
  
  Example inputs for the helm-client-team1.yaml file:
  
  externalServers:
    enabled: true
    hosts: [ "a45c0d48015ed418fbebb1154604f20c-163347652.eu-north-1.elb.amazonaws.com" ]
    tlsServerName: server.dc1.consul
    k8sAuthMethodHost: "587856589C8B28D0DFBC6E0C7DDF16B4D.yl4.eu-north-1.eks.amazonaws.com"
  ...
  client:
    enabled: true
    exposeGossipPorts: true
    join: [ "a45c0d48015ed418fbebb1154604f20c-163347652.eu-north-1.elb.amazonaws.com" ]


8) 5) Run install_consul_client2.sh to deploy Consul Client 2

      ./install_consul_client2.sh
      
Consul should now be install with two separate Kubernetes Clusters belonging to two separate Consul partitions (team1 and team2) 
Teams/tenants can deploy their services in their respective K8s clusters and will be completely isolated from teams and services
in other partitions.

#########
# VIEW UI
#########

To view the Consul UI with a browser, use the EXTERNAL-IP of the consul ui service. 
Note: TLS is enabled in this example, therefore use https:// with port 443.

  kubectl get services consul-consul-ui --context $EKS_CLUSTER_SERVER_CTX
  NAME               TYPE           CLUSTER-IP       EXTERNAL-IP                                                                PORT(S)         
  consul-consul-ui   LoadBalancer   172.20.183.226   a4f396d083ebe43559e2e29582ea3b35-1404433695.eu-north-1.elb.amazonaws.com   443:32563/TCP  

For demo purposes, you can use the boostrap ACL token to log ontn UI. Token can be retrieve with:

  kubectl get secrets/consul-consul-bootstrap-acl-token --template='{{.data.token | base64decode }}' --context $EKS_CLUSTER_SERVER_CTX

In the UI, notice you can toggle between partitions using the Admin Partition box in the upper left side.

#################################
# CROSS PARTITION COMMUNICATION
#################################

This is an example showing a simple app that has a frontend service in the "team1" partition that connects to a backend service in  thw "team1" partition.
We will run through the steps manually so show you exactly how it works.

Navigate to the apps/fakeapp folder.

1) Change context to Kubernetes Client 1 cluster.

  kubectl config use-context $EKS_CLUSTER_CLIENT1_CTX
   
2) Deploy frontend app.

   kubectl apply -f frontend.yaml   

   You should notice the frontend service appear in the Services window from the team1 partition.

3) Export services from partition "team1" to parition "team2".
   
   kubectl apply -f export-front.yaml

3) Change context to Kubernetes Client 2 cluster.

   kubectl config use-context $EKS_CLUSTER_CLIENT2_CTX
   
4) Deploy backend app.

   kubectl apply -f backend.yaml

5) Export services from partition "team2" to parition "team1".
 
   kubectl apply -f export-back.yaml
   
